{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "import warnings\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import mean_squared_error, r2_score, roc_auc_score, confusion_matrix, \\\n",
    "                            accuracy_score, precision_score,recall_score, f1_score                            \n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = 100\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>s_6</th>\n",
       "      <th>s_7</th>\n",
       "      <th>s_8</th>\n",
       "      <th>s_9</th>\n",
       "      <th>s_10</th>\n",
       "      <th>s_11</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
       "0        1            1    -0.0007    -0.0004      100.0  518.67  641.82   \n",
       "1        1            2     0.0019    -0.0003      100.0  518.67  642.15   \n",
       "2        1            3    -0.0043     0.0003      100.0  518.67  642.35   \n",
       "3        1            4     0.0007     0.0000      100.0  518.67  642.35   \n",
       "4        1            5    -0.0019    -0.0002      100.0  518.67  642.37   \n",
       "\n",
       "       s_3      s_4    s_5    s_6     s_7      s_8      s_9  s_10   s_11  \\\n",
       "0  1589.70  1400.60  14.62  21.61  554.36  2388.06  9046.19   1.3  47.47   \n",
       "1  1591.82  1403.14  14.62  21.61  553.75  2388.04  9044.07   1.3  47.49   \n",
       "2  1587.99  1404.20  14.62  21.61  554.26  2388.08  9052.94   1.3  47.27   \n",
       "3  1582.79  1401.87  14.62  21.61  554.45  2388.11  9049.48   1.3  47.13   \n",
       "4  1582.85  1406.22  14.62  21.61  554.00  2388.06  9055.15   1.3  47.28   \n",
       "\n",
       "     s_12     s_13     s_14    s_15  s_16  s_17  s_18   s_19   s_20     s_21  \n",
       "0  521.66  2388.02  8138.62  8.4195  0.03   392  2388  100.0  39.06  23.4190  \n",
       "1  522.28  2388.07  8131.49  8.4318  0.03   392  2388  100.0  39.00  23.4236  \n",
       "2  522.42  2388.03  8133.23  8.4178  0.03   390  2388  100.0  38.95  23.3442  \n",
       "3  522.86  2388.08  8133.83  8.3682  0.03   392  2388  100.0  38.88  23.3739  \n",
       "4  522.19  2388.04  8133.80  8.4294  0.03   393  2388  100.0  38.90  23.4044  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define column names for easy indexing\n",
    "index_names = ['unit_nr', 'time_cycles']\n",
    "setting_names = ['setting_1', 'setting_2', 'setting_3']\n",
    "sensor_names = ['s_{}'.format(i) for i in range(1,22)] \n",
    "col_names = index_names + setting_names + sensor_names\n",
    "# read data\n",
    "train = pd.read_csv('../Data/CMaps/train_FD001.txt',sep='\\s+', header=None, names=col_names)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>s_6</th>\n",
       "      <th>s_7</th>\n",
       "      <th>s_8</th>\n",
       "      <th>s_9</th>\n",
       "      <th>s_10</th>\n",
       "      <th>s_11</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.0</td>\n",
       "      <td>2.063100e+04</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>2.063100e+04</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>2.063100e+04</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>2.063100e+04</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.0</td>\n",
       "      <td>20631.0</td>\n",
       "      <td>20631.000000</td>\n",
       "      <td>20631.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>51.506568</td>\n",
       "      <td>108.807862</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.680934</td>\n",
       "      <td>1590.523119</td>\n",
       "      <td>1408.933782</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>21.609803</td>\n",
       "      <td>553.367711</td>\n",
       "      <td>2388.096652</td>\n",
       "      <td>9065.242941</td>\n",
       "      <td>1.300000e+00</td>\n",
       "      <td>47.541168</td>\n",
       "      <td>521.413470</td>\n",
       "      <td>2388.096152</td>\n",
       "      <td>8143.752722</td>\n",
       "      <td>8.442146</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>393.210654</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.816271</td>\n",
       "      <td>23.289705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>29.227633</td>\n",
       "      <td>68.880990</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.537152e-11</td>\n",
       "      <td>0.500053</td>\n",
       "      <td>6.131150</td>\n",
       "      <td>9.000605</td>\n",
       "      <td>3.394700e-12</td>\n",
       "      <td>0.001389</td>\n",
       "      <td>0.885092</td>\n",
       "      <td>0.070985</td>\n",
       "      <td>22.082880</td>\n",
       "      <td>4.660829e-13</td>\n",
       "      <td>0.267087</td>\n",
       "      <td>0.737553</td>\n",
       "      <td>0.071919</td>\n",
       "      <td>19.076176</td>\n",
       "      <td>0.037505</td>\n",
       "      <td>1.556432e-14</td>\n",
       "      <td>1.548763</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.180746</td>\n",
       "      <td>0.108251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008700</td>\n",
       "      <td>-0.000600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>641.210000</td>\n",
       "      <td>1571.040000</td>\n",
       "      <td>1382.250000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>21.600000</td>\n",
       "      <td>549.850000</td>\n",
       "      <td>2387.900000</td>\n",
       "      <td>9021.730000</td>\n",
       "      <td>1.300000e+00</td>\n",
       "      <td>46.850000</td>\n",
       "      <td>518.690000</td>\n",
       "      <td>2387.880000</td>\n",
       "      <td>8099.940000</td>\n",
       "      <td>8.324900</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.140000</td>\n",
       "      <td>22.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>-0.001500</td>\n",
       "      <td>-0.000200</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.325000</td>\n",
       "      <td>1586.260000</td>\n",
       "      <td>1402.360000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>552.810000</td>\n",
       "      <td>2388.050000</td>\n",
       "      <td>9053.100000</td>\n",
       "      <td>1.300000e+00</td>\n",
       "      <td>47.350000</td>\n",
       "      <td>520.960000</td>\n",
       "      <td>2388.040000</td>\n",
       "      <td>8133.245000</td>\n",
       "      <td>8.414900</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>392.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.700000</td>\n",
       "      <td>23.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>642.640000</td>\n",
       "      <td>1590.100000</td>\n",
       "      <td>1408.040000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>553.440000</td>\n",
       "      <td>2388.090000</td>\n",
       "      <td>9060.660000</td>\n",
       "      <td>1.300000e+00</td>\n",
       "      <td>47.510000</td>\n",
       "      <td>521.480000</td>\n",
       "      <td>2388.090000</td>\n",
       "      <td>8140.540000</td>\n",
       "      <td>8.438900</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>393.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.830000</td>\n",
       "      <td>23.297900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>643.000000</td>\n",
       "      <td>1594.380000</td>\n",
       "      <td>1414.555000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>554.010000</td>\n",
       "      <td>2388.140000</td>\n",
       "      <td>9069.420000</td>\n",
       "      <td>1.300000e+00</td>\n",
       "      <td>47.700000</td>\n",
       "      <td>521.950000</td>\n",
       "      <td>2388.140000</td>\n",
       "      <td>8148.310000</td>\n",
       "      <td>8.465600</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>394.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.950000</td>\n",
       "      <td>23.366800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "      <td>362.000000</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>100.0</td>\n",
       "      <td>5.186700e+02</td>\n",
       "      <td>644.530000</td>\n",
       "      <td>1616.910000</td>\n",
       "      <td>1441.490000</td>\n",
       "      <td>1.462000e+01</td>\n",
       "      <td>21.610000</td>\n",
       "      <td>556.060000</td>\n",
       "      <td>2388.560000</td>\n",
       "      <td>9244.590000</td>\n",
       "      <td>1.300000e+00</td>\n",
       "      <td>48.530000</td>\n",
       "      <td>523.380000</td>\n",
       "      <td>2388.560000</td>\n",
       "      <td>8293.720000</td>\n",
       "      <td>8.584800</td>\n",
       "      <td>3.000000e-02</td>\n",
       "      <td>400.000000</td>\n",
       "      <td>2388.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.430000</td>\n",
       "      <td>23.618400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            unit_nr   time_cycles     setting_1     setting_2  setting_3  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000    20631.0   \n",
       "mean      51.506568    108.807862     -0.000009      0.000002      100.0   \n",
       "std       29.227633     68.880990      0.002187      0.000293        0.0   \n",
       "min        1.000000      1.000000     -0.008700     -0.000600      100.0   \n",
       "25%       26.000000     52.000000     -0.001500     -0.000200      100.0   \n",
       "50%       52.000000    104.000000      0.000000      0.000000      100.0   \n",
       "75%       77.000000    156.000000      0.001500      0.000300      100.0   \n",
       "max      100.000000    362.000000      0.008700      0.000600      100.0   \n",
       "\n",
       "                s_1           s_2           s_3           s_4           s_5  \\\n",
       "count  2.063100e+04  20631.000000  20631.000000  20631.000000  2.063100e+04   \n",
       "mean   5.186700e+02    642.680934   1590.523119   1408.933782  1.462000e+01   \n",
       "std    6.537152e-11      0.500053      6.131150      9.000605  3.394700e-12   \n",
       "min    5.186700e+02    641.210000   1571.040000   1382.250000  1.462000e+01   \n",
       "25%    5.186700e+02    642.325000   1586.260000   1402.360000  1.462000e+01   \n",
       "50%    5.186700e+02    642.640000   1590.100000   1408.040000  1.462000e+01   \n",
       "75%    5.186700e+02    643.000000   1594.380000   1414.555000  1.462000e+01   \n",
       "max    5.186700e+02    644.530000   1616.910000   1441.490000  1.462000e+01   \n",
       "\n",
       "                s_6           s_7           s_8           s_9          s_10  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  2.063100e+04   \n",
       "mean      21.609803    553.367711   2388.096652   9065.242941  1.300000e+00   \n",
       "std        0.001389      0.885092      0.070985     22.082880  4.660829e-13   \n",
       "min       21.600000    549.850000   2387.900000   9021.730000  1.300000e+00   \n",
       "25%       21.610000    552.810000   2388.050000   9053.100000  1.300000e+00   \n",
       "50%       21.610000    553.440000   2388.090000   9060.660000  1.300000e+00   \n",
       "75%       21.610000    554.010000   2388.140000   9069.420000  1.300000e+00   \n",
       "max       21.610000    556.060000   2388.560000   9244.590000  1.300000e+00   \n",
       "\n",
       "               s_11          s_12          s_13          s_14          s_15  \\\n",
       "count  20631.000000  20631.000000  20631.000000  20631.000000  20631.000000   \n",
       "mean      47.541168    521.413470   2388.096152   8143.752722      8.442146   \n",
       "std        0.267087      0.737553      0.071919     19.076176      0.037505   \n",
       "min       46.850000    518.690000   2387.880000   8099.940000      8.324900   \n",
       "25%       47.350000    520.960000   2388.040000   8133.245000      8.414900   \n",
       "50%       47.510000    521.480000   2388.090000   8140.540000      8.438900   \n",
       "75%       47.700000    521.950000   2388.140000   8148.310000      8.465600   \n",
       "max       48.530000    523.380000   2388.560000   8293.720000      8.584800   \n",
       "\n",
       "               s_16          s_17     s_18     s_19          s_20  \\\n",
       "count  2.063100e+04  20631.000000  20631.0  20631.0  20631.000000   \n",
       "mean   3.000000e-02    393.210654   2388.0    100.0     38.816271   \n",
       "std    1.556432e-14      1.548763      0.0      0.0      0.180746   \n",
       "min    3.000000e-02    388.000000   2388.0    100.0     38.140000   \n",
       "25%    3.000000e-02    392.000000   2388.0    100.0     38.700000   \n",
       "50%    3.000000e-02    393.000000   2388.0    100.0     38.830000   \n",
       "75%    3.000000e-02    394.000000   2388.0    100.0     38.950000   \n",
       "max    3.000000e-02    400.000000   2388.0    100.0     39.430000   \n",
       "\n",
       "               s_21  \n",
       "count  20631.000000  \n",
       "mean      23.289705  \n",
       "std        0.108251  \n",
       "min       22.894200  \n",
       "25%       23.221800  \n",
       "50%       23.297900  \n",
       "75%       23.366800  \n",
       "max       23.618400  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 18) True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_7</th>\n",
       "      <th>s_8</th>\n",
       "      <th>s_9</th>\n",
       "      <th>s_11</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>392</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>392</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>390</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>392</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>393</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2     s_2      s_3      s_4  \\\n",
       "0        1            1    -0.0007    -0.0004  641.82  1589.70  1400.60   \n",
       "1        1            2     0.0019    -0.0003  642.15  1591.82  1403.14   \n",
       "2        1            3    -0.0043     0.0003  642.35  1587.99  1404.20   \n",
       "3        1            4     0.0007     0.0000  642.35  1582.79  1401.87   \n",
       "4        1            5    -0.0019    -0.0002  642.37  1582.85  1406.22   \n",
       "\n",
       "      s_7      s_8      s_9   s_11    s_12     s_13    s_15  s_17   s_20  \\\n",
       "0  554.36  2388.06  9046.19  47.47  521.66  2388.02  8.4195   392  39.06   \n",
       "1  553.75  2388.04  9044.07  47.49  522.28  2388.07  8.4318   392  39.00   \n",
       "2  554.26  2388.08  9052.94  47.27  522.42  2388.03  8.4178   390  38.95   \n",
       "3  554.45  2388.11  9049.48  47.13  522.86  2388.08  8.3682   392  38.88   \n",
       "4  554.00  2388.06  9055.15  47.28  522.19  2388.04  8.4294   393  38.90   \n",
       "\n",
       "      s_21  RUL  \n",
       "0  23.4190  191  \n",
       "1  23.4236  190  \n",
       "2  23.3442  189  \n",
       "3  23.3739  188  \n",
       "4  23.4044  187  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove those column as we can see that it's value is not changing\n",
    "cols_to_drop = ['setting_3', 's_1', 's_5', 's_6', 's_10', 's_14', 's_16', 's_18', 's_19']\n",
    "train=train.drop(cols_to_drop, axis=1)\n",
    "# Adding RUL (Remining Useful Life) to the train dataset\n",
    "def add_remaining_useful_life(df):\n",
    "    # Get the total number of cycles for each unit\n",
    "    grouped_by_unit = df.groupby(by=\"unit_nr\")\n",
    "    max_cycle = grouped_by_unit[\"time_cycles\"].max()    \n",
    "    # Merge the max cycle back into the original frame\n",
    "    result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='unit_nr', right_index=True)    \n",
    "    # Calculate remaining useful life for each row\n",
    "    remaining_useful_life = result_frame[\"max_cycle\"] - result_frame[\"time_cycles\"]\n",
    "    result_frame[\"RUL\"] = remaining_useful_life    \n",
    "    # drop max_cycle as it's no longer needed\n",
    "    result_frame = result_frame.drop(\"max_cycle\", axis=1)\n",
    "    return result_frame\n",
    "train = add_remaining_useful_life(train)\n",
    "#train[sensor_names+['RUL']].head()\n",
    "print(train.shape, (train.isna().sum()==0).all())\n",
    "train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'RUL')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'frequency')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# distribution of RUL, similar to the 'describe function' of time_cycles above, but visual\n",
    "df_max_rul = train[['unit_nr', 'RUL']].groupby('unit_nr').max().reset_index()\n",
    "df_max_rul['RUL'].hist(bins=15, figsize=(10,6))\n",
    "plt.xlabel('RUL')\n",
    "plt.ylabel('frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10     20.0\n",
       "0.25     51.0\n",
       "0.50    103.0\n",
       "0.75    155.0\n",
       "0.90    198.0\n",
       "Name: RUL, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how values RUL are distributed into various quantiles.\n",
    "train['RUL'].quantile([.1, .25, .5, .75, 0.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 19)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Attention_Required\n",
       "1    Attention_Required\n",
       "2    Attention_Required\n",
       "3    Attention_Required\n",
       "4    Attention_Required\n",
       "Name: Class, dtype: category\n",
       "Categories (4, object): ['Inception' < 'Healthy' < 'Mature' < 'Attention_Required']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Class'] = pd.cut(x=train['RUL'], bins=[-1,51,103,155,361], labels=['Inception','Healthy','Mature','Attention_Required'])\n",
    "print(train.shape)\n",
    "train.Class.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[ 29  94   6  67  66  36  17  50  35   8  96  28  20  82  26  63  14  25\n",
      "   4  18  39   9  79   7  65  37  90  57 100  55  44  51  68  47  69  62\n",
      "  98  80  42  59  49  99  58  76  33  95  60  64  85  38  30   2  53  22\n",
      "   3  24  88  92  75  87  83  21  61  72  15  93  52] [84 54 71 46 45 40 23 81 11  1 19 31 74 34 91  5 77 78 13 32 56 89 27 43\n",
      " 70 16 41 97 10 73 12 48 86]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13828, 15), (6803, 15), (13828,), (6803,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting of Independent & Dependent Variable and train input and output data\n",
    "print(len(train['unit_nr'].unique()))\n",
    "train_id, validate_id = train_test_split(train['unit_nr'].unique(), test_size=0.33, random_state=42)\n",
    "print(train_id, validate_id)\n",
    "X_train = train[train['unit_nr'].isin(train_id)]\n",
    "X_validate = train[train['unit_nr'].isin(validate_id)]\n",
    "y_train = train[train['unit_nr'].isin(train_id)].Class\n",
    "y_validate = train[train['unit_nr'].isin(validate_id)].Class\n",
    "X_train = X_train.drop(axis=0, columns=['Class','unit_nr','time_cycles','RUL'])\n",
    "X_validate = X_validate.drop(axis=0, columns=['Class','unit_nr','time_cycles','RUL'])\n",
    "X_train.shape, X_validate.shape, y_train.shape, y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 2 2 2] [0 0 0 ... 2 2 2]\n",
      "[10:48:43] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "              verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "              verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = len(train.Class.unique())\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_validate = le.fit_transform(y_validate)\n",
    "print(y_train, y_validate)\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, X, y, set=\"train\"):\n",
    "    y_hat = model.predict(X)\n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    y_lb = lb.fit_transform(y)\n",
    "    y_hat_lb = lb.transform(y_hat)\n",
    "    #print(y_lb, y_hat_lb)\n",
    "    print(f\"roc score for {set} dataset: \", roc_auc_score(y_lb, y_hat_lb, average='macro'))\n",
    "    print(f'Acc Score for {set} dataset: ', accuracy_score(y_lb, y_hat_lb))\n",
    "    print(f'Precision Score for {set} dataset: ', precision_score(y_lb, y_hat_lb, average='macro'))\n",
    "    print(f'Recall Score for {set} dataset: ', recall_score(y_lb, y_hat_lb, average='macro'))\n",
    "    print(f'f1 score for {set} dataset: ', f1_score(y_lb, y_hat_lb, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score for train dataset:  0.9406385447024939\n",
      "Acc Score for train dataset:  0.9111223604281169\n",
      "Precision Score for train dataset:  0.9130374238034707\n",
      "Recall Score for train dataset:  0.9108833777281111\n",
      "f1 score for train dataset:  0.911044701705492\n",
      "roc score for validate dataset:  0.7182812961598686\n",
      "Acc Score for validate dataset:  0.5784212847273262\n",
      "Precision Score for validate dataset:  0.5727010028946317\n",
      "Recall Score for validate dataset:  0.5769952904091421\n",
      "f1 score for validate dataset:  0.574206643360785\n"
     ]
    }
   ],
   "source": [
    "evaluation(xgb, X_train, y_train, set='train')\n",
    "evaluation(xgb, X_validate, y_validate, set='validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected Output</th>\n",
       "      <th>Predicted Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6798</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6799</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6800</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6801</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Expected Output  Predicted Output\n",
       "6798                2                 2\n",
       "6799                2                 2\n",
       "6800                2                 2\n",
       "6801                2                 2\n",
       "6802                2                 2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final Results in the form of dataset\n",
    "output = pd.DataFrame()\n",
    "output['Expected Output'] = y_validate\n",
    "output['Predicted Output'] = xgb.predict(X_validate)\n",
    "output.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>setting_3</th>\n",
       "      <th>s_1</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_5</th>\n",
       "      <th>s_6</th>\n",
       "      <th>s_7</th>\n",
       "      <th>s_8</th>\n",
       "      <th>s_9</th>\n",
       "      <th>s_10</th>\n",
       "      <th>s_11</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_14</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_16</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_18</th>\n",
       "      <th>s_19</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.02</td>\n",
       "      <td>1585.29</td>\n",
       "      <td>1398.21</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.90</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9050.17</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.20</td>\n",
       "      <td>521.72</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8125.55</td>\n",
       "      <td>8.4052</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.86</td>\n",
       "      <td>23.3735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.0027</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.71</td>\n",
       "      <td>1588.45</td>\n",
       "      <td>1395.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.85</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>9054.42</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.50</td>\n",
       "      <td>522.16</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>8139.62</td>\n",
       "      <td>8.3803</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.02</td>\n",
       "      <td>23.3916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.46</td>\n",
       "      <td>1586.94</td>\n",
       "      <td>1401.34</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.11</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>9056.96</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.50</td>\n",
       "      <td>521.97</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8130.10</td>\n",
       "      <td>8.4441</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.08</td>\n",
       "      <td>23.4166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.44</td>\n",
       "      <td>1584.12</td>\n",
       "      <td>1406.42</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.07</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>9045.29</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "      <td>521.38</td>\n",
       "      <td>2388.05</td>\n",
       "      <td>8132.90</td>\n",
       "      <td>8.3917</td>\n",
       "      <td>0.03</td>\n",
       "      <td>391</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.3737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.51</td>\n",
       "      <td>1587.19</td>\n",
       "      <td>1401.92</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.16</td>\n",
       "      <td>2388.01</td>\n",
       "      <td>9044.55</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.31</td>\n",
       "      <td>522.15</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8129.54</td>\n",
       "      <td>8.4031</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.99</td>\n",
       "      <td>23.4130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2  setting_3     s_1     s_2  \\\n",
       "0        1            1     0.0023     0.0003      100.0  518.67  643.02   \n",
       "1        1            2    -0.0027    -0.0003      100.0  518.67  641.71   \n",
       "2        1            3     0.0003     0.0001      100.0  518.67  642.46   \n",
       "3        1            4     0.0042     0.0000      100.0  518.67  642.44   \n",
       "4        1            5     0.0014     0.0000      100.0  518.67  642.51   \n",
       "\n",
       "       s_3      s_4    s_5    s_6     s_7      s_8      s_9  s_10   s_11  \\\n",
       "0  1585.29  1398.21  14.62  21.61  553.90  2388.04  9050.17   1.3  47.20   \n",
       "1  1588.45  1395.42  14.62  21.61  554.85  2388.01  9054.42   1.3  47.50   \n",
       "2  1586.94  1401.34  14.62  21.61  554.11  2388.05  9056.96   1.3  47.50   \n",
       "3  1584.12  1406.42  14.62  21.61  554.07  2388.03  9045.29   1.3  47.28   \n",
       "4  1587.19  1401.92  14.62  21.61  554.16  2388.01  9044.55   1.3  47.31   \n",
       "\n",
       "     s_12     s_13     s_14    s_15  s_16  s_17  s_18   s_19   s_20     s_21  \n",
       "0  521.72  2388.03  8125.55  8.4052  0.03   392  2388  100.0  38.86  23.3735  \n",
       "1  522.16  2388.06  8139.62  8.3803  0.03   393  2388  100.0  39.02  23.3916  \n",
       "2  521.97  2388.03  8130.10  8.4441  0.03   393  2388  100.0  39.08  23.4166  \n",
       "3  521.38  2388.05  8132.90  8.3917  0.03   391  2388  100.0  39.00  23.3737  \n",
       "4  522.15  2388.03  8129.54  8.4031  0.03   390  2388  100.0  38.99  23.4130  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('../Data/CMaps/test_FD001.txt', sep='\\s+', header=None, names=col_names)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 17)\n",
      "100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(100, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = test.groupby('unit_nr').last().reset_index().drop(cols_to_drop, axis=1)\n",
    "print(X_test.shape)\n",
    "num_test_machines = len(X_test.unit_nr.unique())\n",
    "print(num_test_machines)\n",
    "X_test = X_test.drop(axis=0, columns=['unit_nr', 'time_cycles'])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul_pred = xgb.predict(X_test).reshape(-1)\n",
    "rul_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUL</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>117</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    RUL  Class\n",
       "95  137      2\n",
       "96   82      0\n",
       "97   59      0\n",
       "98  117      2\n",
       "99   20      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = pd.read_csv('../Data/CMaps/RUL_FD001.txt', delim_whitespace=True, names=[\"RUL\"])\n",
    "print(y_true.shape)\n",
    "y_true['Class'] = pd.cut(x=y_true['RUL'], bins=[-1,51,103,155,361], labels=['Inception','Healthy','Mature','Attention_Required'])\n",
    "y_true['Class'] = le.fit_transform(y_true['Class'])\n",
    "y_true.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score for test dataset:  0.37730387357253026\n",
      "Acc Score for test dataset:  0.1\n",
      "Precision Score for test dataset:  0.15333333333333332\n",
      "Recall Score for test dataset:  0.09754689754689755\n",
      "f1 score for test dataset:  0.11870428422152558\n"
     ]
    }
   ],
   "source": [
    "evaluation(xgb, X_test, y_true.Class, set=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_class=4,\n",
       "               num_leaves=100, objective=&#x27;multiclass&#x27;, random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_class=4,\n",
       "               num_leaves=100, objective=&#x27;multiclass&#x27;, random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_class=4,\n",
       "               num_leaves=100, objective='multiclass', random_state=50)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score for train dataset:  1.0\n",
      "Acc Score for train dataset:  1.0\n",
      "Precision Score for train dataset:  1.0\n",
      "Recall Score for train dataset:  1.0\n",
      "f1 score for train dataset:  1.0\n",
      "roc score for validate dataset:  0.7122959495362243\n",
      "Acc Score for validate dataset:  0.5694546523592533\n",
      "Precision Score for validate dataset:  0.5652773369522752\n",
      "Recall Score for validate dataset:  0.5680030090077708\n",
      "f1 score for validate dataset:  0.5661044684621861\n",
      "roc score for test dataset:  0.37267970542773\n",
      "Acc Score for test dataset:  0.1\n",
      "Precision Score for test dataset:  0.135632183908046\n",
      "Recall Score for test dataset:  0.09870129870129869\n",
      "f1 score for test dataset:  0.11300097751710654\n"
     ]
    }
   ],
   "source": [
    "lgmb = LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_leaves=100, num_class=num_of_classes,\n",
    "                          objective='multiclass', random_state=50, n_jobs=-1)\n",
    "lgmb.fit(X_train, y_train)\n",
    "evaluation(lgmb, X_train, y_train, set='train')\n",
    "evaluation(lgmb, X_validate, y_validate, set='validate')\n",
    "evaluation(lgmb, X_test, y_true.Class, set=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20631, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_nr</th>\n",
       "      <th>time_cycles</th>\n",
       "      <th>setting_1</th>\n",
       "      <th>setting_2</th>\n",
       "      <th>s_2</th>\n",
       "      <th>s_3</th>\n",
       "      <th>s_4</th>\n",
       "      <th>s_7</th>\n",
       "      <th>s_8</th>\n",
       "      <th>s_9</th>\n",
       "      <th>s_11</th>\n",
       "      <th>s_12</th>\n",
       "      <th>s_13</th>\n",
       "      <th>s_15</th>\n",
       "      <th>s_17</th>\n",
       "      <th>s_20</th>\n",
       "      <th>s_21</th>\n",
       "      <th>RUL</th>\n",
       "      <th>Class</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>392</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "      <td>Attention_Required</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>392</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "      <td>Attention_Required</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>390</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "      <td>Attention_Required</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>392</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "      <td>Attention_Required</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>393</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "      <td>Attention_Required</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   unit_nr  time_cycles  setting_1  setting_2     s_2      s_3      s_4  \\\n",
       "0        1            1    -0.0007    -0.0004  641.82  1589.70  1400.60   \n",
       "1        1            2     0.0019    -0.0003  642.15  1591.82  1403.14   \n",
       "2        1            3    -0.0043     0.0003  642.35  1587.99  1404.20   \n",
       "3        1            4     0.0007     0.0000  642.35  1582.79  1401.87   \n",
       "4        1            5    -0.0019    -0.0002  642.37  1582.85  1406.22   \n",
       "\n",
       "      s_7      s_8      s_9   s_11    s_12     s_13    s_15  s_17   s_20  \\\n",
       "0  554.36  2388.06  9046.19  47.47  521.66  2388.02  8.4195   392  39.06   \n",
       "1  553.75  2388.04  9044.07  47.49  522.28  2388.07  8.4318   392  39.00   \n",
       "2  554.26  2388.08  9052.94  47.27  522.42  2388.03  8.4178   390  38.95   \n",
       "3  554.45  2388.11  9049.48  47.13  522.86  2388.08  8.3682   392  38.88   \n",
       "4  554.00  2388.06  9055.15  47.28  522.19  2388.04  8.4294   393  38.90   \n",
       "\n",
       "      s_21  RUL               Class  class_1  class_2  \n",
       "0  23.4190  191  Attention_Required        0        0  \n",
       "1  23.4236  190  Attention_Required        0        0  \n",
       "2  23.3442  189  Attention_Required        0        0  \n",
       "3  23.3739  188  Attention_Required        0        0  \n",
       "4  23.4044  187  Attention_Required        0        0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to try the same multi-class with deep learning used one\n",
    "train['class_1'] = [1 if i < 50 else 0 for i in train.RUL]\n",
    "train['class_2'] = train['class_1']\n",
    "train['class_2'] = np.where(train.RUL < 25, 2, train['class_2'])\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "[ 29  94   6  67  66  36  17  50  35   8  96  28  20  82  26  63  14  25\n",
      "   4  18  39   9  79   7  65  37  90  57 100  55  44  51  68  47  69  62\n",
      "  98  80  42  59  49  99  58  76  33  95  60  64  85  38  30   2  53  22\n",
      "   3  24  88  92  75  87  83  21  61  72  15  93  52] [84 54 71 46 45 40 23 81 11  1 19 31 74 34 91  5 77 78 13 32 56 89 27 43\n",
      " 70 16 41 97 10 73 12 48 86]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((13828, 15), (6803, 15), (13828,), (6803,))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting of Independent & Dependent Variable and train input and output data\n",
    "print(len(train['unit_nr'].unique()))\n",
    "train_id, validate_id = train_test_split(train['unit_nr'].unique(), test_size=0.33, random_state=42)\n",
    "print(train_id, validate_id)\n",
    "X_train = train[train['unit_nr'].isin(train_id)]\n",
    "X_validate = train[train['unit_nr'].isin(validate_id)]\n",
    "y_train = train[train['unit_nr'].isin(train_id)].class_2\n",
    "y_validate = train[train['unit_nr'].isin(validate_id)].class_2\n",
    "X_train = X_train.drop(axis=0, columns=['class_1','class_2','Class','unit_nr','time_cycles','RUL'])\n",
    "X_validate = X_validate.drop(axis=0, columns=['class_1','class_2','Class','unit_nr','time_cycles','RUL'])\n",
    "X_train.shape, X_validate.shape, y_train.shape, y_validate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:58:19] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "              verbosity=None)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=0.5, booster=&#x27;gbtree&#x27;, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints=&#x27;&#x27;, learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=&#x27;()&#x27;, n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective=&#x27;multi:softprob&#x27;, predictor=&#x27;auto&#x27;,\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method=&#x27;exact&#x27;, validate_parameters=1,\n",
       "              verbosity=None)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
       "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
       "              subsample=1, tree_method='exact', validate_parameters=1,\n",
       "              verbosity=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_classes = len(train.class_2.unique())\n",
    "xgb.fit(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score for train dataset:  0.9923584393230994\n",
      "Acc Score for train dataset:  0.9962395140295054\n",
      "Precision Score for train dataset:  0.9981801301535344\n",
      "Recall Score for train dataset:  0.9898189335817572\n",
      "f1 score for train dataset:  0.9939223136823823\n",
      "roc score for validate dataset:  0.8620187663841733\n",
      "Acc Score for validate dataset:  0.8988681464059973\n",
      "Precision Score for validate dataset:  0.797774169218935\n",
      "Recall Score for validate dataset:  0.7973566050569737\n",
      "f1 score for validate dataset:  0.7973695361225452\n"
     ]
    }
   ],
   "source": [
    "evaluation(xgb, X_train, y_train, set='train')\n",
    "evaluation(xgb, X_validate, y_validate, set='validate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Expected Output2</th>\n",
       "      <th>Predicted Output2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20085</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20086</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20087</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20088</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20089</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Expected Output2  Predicted Output2\n",
       "20085                 2                  2\n",
       "20086                 2                  2\n",
       "20087                 2                  2\n",
       "20088                 2                  2\n",
       "20089                 2                  2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = pd.DataFrame()\n",
    "output['Expected Output2'] = y_validate\n",
    "output['Predicted Output2'] = xgb.predict(X_validate)\n",
    "output.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul_pred2 = xgb.predict(X_test).reshape(-1)\n",
    "rul_pred2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n",
      "(100, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RUL</th>\n",
       "      <th>class_1</th>\n",
       "      <th>class_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>98</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>69</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RUL  class_1  class_2\n",
       "0  112        0        0\n",
       "1   98        0        0\n",
       "2   69        0        0\n",
       "3   82        0        0\n",
       "4   91        0        0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = pd.read_csv('../Data/CMaps/RUL_FD001.txt', delim_whitespace=True, names=[\"RUL\"])\n",
    "print(y_test.shape)\n",
    "# we want to try the same multi-class with deep learning used one\n",
    "y_test['class_1'] = [1 if i < 50 else 0 for i in y_test.RUL]\n",
    "y_test['class_2'] = y_test['class_1']\n",
    "y_test['class_2'] = np.where(y_test.RUL < 25, 2, y_test['class_2'])\n",
    "print(y_test.shape)\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score for test dataset:  0.8237313734784003\n",
      "Acc Score for test dataset:  0.87\n",
      "Precision Score for test dataset:  0.7558179837591602\n",
      "Recall Score for test dataset:  0.7337206652996127\n",
      "f1 score for test dataset:  0.743846919903258\n"
     ]
    }
   ],
   "source": [
    "evaluation(xgb, X_test, y_test.class_2, set=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67,  3,  0],\n",
       "       [ 4,  5,  2],\n",
       "       [ 1,  3, 15]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test.class_2, rul_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_class=3,\n",
       "               num_leaves=100, objective=&#x27;multiclass&#x27;, random_state=50)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_class=3,\n",
       "               num_leaves=100, objective=&#x27;multiclass&#x27;, random_state=50)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_class=3,\n",
       "               num_leaves=100, objective='multiclass', random_state=50)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roc score for train dataset:  1.0\n",
      "Acc Score for train dataset:  1.0\n",
      "Precision Score for train dataset:  1.0\n",
      "Recall Score for train dataset:  1.0\n",
      "f1 score for train dataset:  1.0\n",
      "roc score for validate dataset:  0.8525063172198853\n",
      "Acc Score for validate dataset:  0.89519329707482\n",
      "Precision Score for validate dataset:  0.7890303308818569\n",
      "Recall Score for validate dataset:  0.7825046506203114\n",
      "f1 score for validate dataset:  0.7853568932754594\n",
      "roc score for test dataset:  0.8366868902416572\n",
      "Acc Score for test dataset:  0.87\n",
      "Precision Score for test dataset:  0.7762053087757312\n",
      "Recall Score for test dataset:  0.7592617908407382\n",
      "f1 score for test dataset:  0.7644376899696049\n"
     ]
    }
   ],
   "source": [
    "lgmb2 = LGBMClassifier(learning_rate=0.01, n_estimators=5000, num_leaves=100, num_class=num_of_classes,\n",
    "                      objective='multiclass', random_state=50, n_jobs=-1)\n",
    "lgmb2.fit(X_train, y_train)\n",
    "evaluation(lgmb2, X_train, y_train, set='train')\n",
    "evaluation(lgmb2, X_validate, y_validate, set='validate')\n",
    "evaluation(lgmb2, X_test, y_test.class_2, set=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[66,  4,  0],\n",
       "       [ 4,  6,  1],\n",
       "       [ 1,  3, 15]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rul_pred3 = lgmb2.predict(X_test).reshape(-1)\n",
    "confusion_matrix(y_test.class_2, rul_pred3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "cc71ba6e435d9d09198655da37cebfd27b8e5d7a82fa47eb2e097fb9cde69c47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
